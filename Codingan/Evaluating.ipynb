{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, StorageContext, load_index_from_storage, Document, Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core import ServiceContext\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoModelForSeq2SeqLM, AutoModel\n",
    "from llama_index.core.prompts.prompts import SimpleInputPrompt\n",
    "import torch\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['OPENAI_API_KEY'] = ''\n",
    "model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "model_path = '../Model/tinylmma-1b'\n",
    "model_name_litteral = \"tinylmma-1b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = SimpleDirectoryReader('../Summarizer result/').load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=1, model=\"gpt-3.5-turbo-16k\")\n",
    "# service_context = ServiceContext.from_defaults(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name google-bert/bert-base-uncased. Creating a new one with MEAN pooling.\n",
      "c:\\Users\\Frederick\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4760702e62044ce8a865317fd22b369d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Frederick\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Frederick\\AppData\\Local\\llama_index\\models--google-bert--bert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a57de3de00c9454c95884ecd7f111d61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98db32c95a5048c5a23c316772a1f1ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe5bb53dc36f44bfa0a3fd3dd4c13ba4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dafdf189c634f08bf9178eaf730b0a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(\n",
    "    model_name=\"google-bert/bert-base-uncased\", \n",
    "    device=\"cuda\",\n",
    "    max_length=2048\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.embed_model = embed_model # Load using embended model that has been defined\n",
    "storage_context = StorageContext.from_defaults(persist_dir=\"../VectorizedData/bart-base/\" ) #isi dengan directory tempat dataset\n",
    "index = load_index_from_storage(storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model `google/flan-t5-large` and tokenizer `StabilityAI/stablelm-tuned-alpha-3b` are different, please ensure that they are compatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask_token_id: None\n",
      "sep_token_id: None\n",
      "pad_token_id: 0\n",
      "eos_token_id: 1\n",
      "cls_token_id: None\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "from llama_index.core.prompts.prompts import SimpleInputPrompt\n",
    "\n",
    "system_prompt = \"\"\"# Flan Model\n",
    "- The Flan Model is a multifunctional language model engineered for a range of applications, including gaming-related tasks.\n",
    "- This model excels at managing a variety of queries and producing precise, contextually appropriate responses in various settings, including gaming platforms such as Steam.\n",
    "- Flan Model utilizes an advanced architecture customized for optimal performance in natural language processing, guaranteeing swift text processing and rapid response times in gaming interactions.\n",
    "\"\"\"\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "query_wrapper_prompt = SimpleInputPrompt(\"{query_str}\")\n",
    "\n",
    "# Initialize the HuggingFaceLLM\n",
    "localLLM = HuggingFaceLLM(\n",
    "    context_window=450, \n",
    "    max_new_tokens=100,\n",
    "    system_prompt=system_prompt,\n",
    "    generate_kwargs={\"temperature\": 0.2, \"do_sample\": True},\n",
    "    model_name=model_name,\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    tokenizer_kwargs={\"max_length\": 750, \"truncation\": True},\n",
    "    model_kwargs={\"torch_dtype\": torch.float32, \"pad_token_id\": tokenizer.pad_token_id, \"device\": \"cuda\"},\n",
    ")\n",
    "\n",
    "print(\"mask_token_id:\", tokenizer.mask_token_id)\n",
    "print(\"sep_token_id:\", tokenizer.sep_token_id)\n",
    "print(\"pad_token_id:\", tokenizer.pad_token_id)\n",
    "print(\"eos_token_id:\", tokenizer.eos_token_id)\n",
    "print(\"cls_token_id:\", tokenizer.cls_token_id)\n",
    "query_engine = index.as_query_engine(similarity_top_k=3, llm=localLLM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BatchEvalRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.evaluation import (\n",
    "    FaithfulnessEvaluator,\n",
    "    RelevancyEvaluator,\n",
    "    CorrectnessEvaluator,\n",
    ")\n",
    "from llama_index.core.evaluation import DatasetGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "faithfulness = FaithfulnessEvaluator(llm=localLLM)\n",
    "relevancy = RelevancyEvaluator(llm=localLLM)\n",
    "correctness = CorrectnessEvaluator(llm=localLLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Frederick\\anaconda3\\lib\\site-packages\\llama_index\\core\\evaluation\\dataset_generation.py:213: DeprecationWarning: Call to deprecated class DatasetGenerator. (Deprecated in favor of `RagDatasetGenerator` which should be used instead.)\n",
      "  return cls(\n",
      "c:\\Users\\Frederick\\anaconda3\\lib\\site-packages\\llama_index\\core\\evaluation\\dataset_generation.py:310: DeprecationWarning: Call to deprecated class QueryResponseDataset. (Deprecated in favor of `LabelledRagDataset` which should be used instead.)\n",
      "  return QueryResponseDataset(queries=queries, responses=responses_dict)\n"
     ]
    }
   ],
   "source": [
    "dataset_generator = DatasetGenerator.from_documents(docs, llm=localLLM)\n",
    "\n",
    "qas = dataset_generator.generate_dataset_from_nodes(num=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of embeddings: 768\n"
     ]
    }
   ],
   "source": [
    "embeddings = embed_model.get_text_embedding(\"hi abc\")\n",
    "print(f\"Dimension of embeddings: {len(embeddings)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.evaluation import BatchEvalRunner\n",
    "\n",
    "runner = BatchEvalRunner(\n",
    "    {\"faithfulness\": faithfulness, \"relevancy\": relevancy},\n",
    "    workers=8,\n",
    ")\n",
    "\n",
    "eval_results = await runner.aevaluate_queries(\n",
    "    index.as_query_engine(similarity_top_k=3, llm=localLLM), queries=qas.questions\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval_results(key, eval_results):\n",
    "    results = eval_results[key]\n",
    "    correct = 0\n",
    "    for result in results:\n",
    "        if result.passing:\n",
    "            correct += 1\n",
    "    score = correct / len(results)\n",
    "    print(f\"{key} Score: {score}\")\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correcteness Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.evaluation import CorrectnessEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "llmGPT = OpenAI(temperature=1, model=\"gpt-3.5-turbo-16k\")\n",
    "evaluator = CorrectnessEvaluator(llm=llmGPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    (\n",
    "        \"Can you describe the gameplay of Stardew Valley in detail?\",\n",
    "        \"\"\"\n",
    "        In Stardew Valley, players inherit a run-down farm and must restore it by planting crops, raising animals, mining, fishing, and crafting. They also interact with the local townspeople, build relationships, and participate in seasonal events. The game combines farming simulation with social elements and offers a variety of activities to engage in throughout the in-game year.\n",
    "        \"\"\"\n",
    "    ),\n",
    "    (\n",
    "        \"What is the storyline of Doki Doki Literature Club?\",\n",
    "        \"\"\"\n",
    "        Doki Doki Literature Club starts as a lighthearted dating sim where you join a high school literature club and interact with four female members. However, the game takes a dark turn, revealing psychological horror elements as it progresses. The story delves into themes of mental illness, manipulation, and the breaking of the fourth wall.\n",
    "        \"\"\"\n",
    "    ),\n",
    "    (\n",
    "        \"What is the main gameplay of Celeste?\",\n",
    "        \"\"\"\n",
    "        Celeste is a platformer game where players control a character named Madeline as she climbs a mountain. The gameplay focuses on precise jumping, dashing, and climbing mechanics, with challenging levels designed to test the player's skills. The game also explores themes of mental health, perseverance, and self-discovery through its narrative.\n",
    "        \"\"\"\n",
    "    ),\n",
    "    (\n",
    "        \"What is the basic premise of Hollow Knight?\",\n",
    "        \"\"\"\n",
    "        Hollow Knight is an action-adventure game set in the mysterious, underground kingdom of Hallownest. Players control a silent, insect-like knight who explores a vast, interconnected world filled with secrets, enemies, and powerful bosses. The game features tight platforming, combat, and an emphasis on exploration and discovery.\n",
    "        \"\"\"\n",
    "    ),\n",
    "    (\n",
    "        \"What is the gameplay style of Hades?\",\n",
    "        \"\"\"\n",
    "        Hades is a rogue-like dungeon crawler where players control Zagreus, the son of Hades, as he attempts to escape the Underworld. The game features fast-paced combat, with a variety of weapons and abilities to choose from. Each escape attempt is procedurally generated, offering unique challenges and rewards. The game also includes a strong narrative element, with characters and storylines that develop over multiple runs.\n",
    "        \"\"\"\n",
    "    ),\n",
    "    (\n",
    "        \"What is the unique aspect of Undertale's gameplay?\",\n",
    "        \"\"\"\n",
    "        Undertale is an RPG where players control a child who has fallen into the Underground, a world filled with monsters. The game is known for its unique combat system, which allows players to choose between fighting or peacefully resolving conflicts with enemies. The choices players make significantly impact the game's story and outcomes, leading to multiple possible endings.\n",
    "        \"\"\"\n",
    "    ),\n",
    "    (\n",
    "        \"What makes The Legend of Zelda: Breath of the Wild unique?\",\n",
    "        \"\"\"\n",
    "        The Legend of Zelda: Breath of the Wild is an open-world action-adventure game set in the kingdom of Hyrule. Players control Link as he explores a vast, open world filled with diverse landscapes, enemies, and puzzles. The game emphasizes freedom and player choice, allowing players to tackle challenges in any order and experiment with different strategies and solutions. The game also features a dynamic weather system and physics-based interactions.\n",
    "        \"\"\"\n",
    "    ),\n",
    "    (\n",
    "        \"What is the gameplay experience of Dark Souls like?\",\n",
    "        \"\"\"\n",
    "        Dark Souls is an action RPG known for its challenging difficulty and deep lore. Players control a customizable character who explores a dark, interconnected world filled with deadly enemies and bosses. Combat is deliberate and requires precise timing and strategy. The game also features a unique multiplayer system where players can leave messages, assist, or invade other players' worlds.\n",
    "        \"\"\"\n",
    "    ),\n",
    "    (\n",
    "        \"What is the main focus of The Witcher 3: Wild Hunt?\",\n",
    "        \"\"\"\n",
    "        The Witcher 3: Wild Hunt is an open-world RPG that follows Geralt of Rivia, a monster hunter, as he searches for his adopted daughter, Ciri. The game features a vast, detailed world filled with quests, monsters, and characters. The story is highly immersive, with branching narratives and meaningful choices that affect the outcome. Combat involves a mix of swordplay, magic, and alchemy.\n",
    "        \"\"\"\n",
    "    ),\n",
    "    (\n",
    "        \"What is the gameplay of Portal 2?\",\n",
    "        \"\"\"\n",
    "        Portal 2 is a first-person puzzle-platform game where players control Chell, a test subject in the Aperture Science facility. The gameplay revolves around using a portal gun to create linked portals on surfaces, solving puzzles, and navigating through the facility. The game features a single-player campaign with a rich narrative and a cooperative multiplayer mode with unique puzzles designed for two players.\n",
    "        \"\"\"\n",
    "    ),\n",
    "]\n",
    "dataset = [\n",
    "    {\"query\": \"What do players do in 'Stardew Valley'?\", \"ground_truth\": \"Players farm, raise animals, and make friends with townsfolk.\"},\n",
    "    {\"query\": \"What is surprising about 'Doki Doki Literature Club'?\", \"ground_truth\": \"It turns from a dating sim into a psychological horror game.\"},\n",
    "    {\"query\": \"What can players choose to do instead of fighting in 'Undertale'?\", \"ground_truth\": \"Players can choose to befriend enemies.\"},\n",
    "    {\"query\": \"What do players love about 'Hades'?\", \"ground_truth\": \"Players love the exciting rogue-like gameplay and interesting story.\"},\n",
    "    {\"query\": \"How is the world in 'The Witcher 3: Wild Hunt' described?\", \"ground_truth\": \"The world is detailed and immersive.\"},\n",
    "    {\"query\": \"What is challenging in 'Celeste'?\", \"ground_truth\": \"The platforming levels are very challenging.\"},\n",
    "    {\"query\": \"What do players often praise in 'Hollow Knight'?\", \"ground_truth\": \"Players praise the detailed levels and deep story.\"},\n",
    "    {\"query\": \"What tool is central to 'Portal'?\", \"ground_truth\": \"The portal gun is central to solving puzzles.\"},\n",
    "    {\"query\": \"What do players like about 'Slay the Spire'?\", \"ground_truth\": \"Players like the strategy of building and using card decks.\"},\n",
    "    {\"query\": \"What is special about 'Disco Elysium'?\", \"ground_truth\": \"It has a deep story with lots of choices.\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "CorrectScore = 0.0\n",
    "for i in range(10):\n",
    "    response = query_engine.query(queries[i][0])\n",
    "    result = evaluator.evaluate(\n",
    "        query = queries[i][0],\n",
    "        response=str(response),\n",
    "        reference=queries[i][1]\n",
    "    )\n",
    "    print(result.score)\n",
    "    CorrectScore+=result.score\n",
    "CorrectScore = CorrectScore/10.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Exact Match (EM): 0.0\n",
      "Average F1 Score: 0.10992676191317956\n",
      "Average Recall: 0.9150356282864024\n",
      "Average Precision: 0.6487986488473867\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def calculate_exact_match(response, ground_truth):\n",
    "    return int(response.strip().lower() == ground_truth.strip().lower())\n",
    "\n",
    "def calculate_f1(response, ground_truth):\n",
    "    response_tokens = response.lower().split()\n",
    "    ground_truth_tokens = ground_truth.lower().split()\n",
    "    common = Counter(response_tokens) & Counter(ground_truth_tokens)\n",
    "    num_same = sum(common.values())\n",
    "\n",
    "    if num_same == 0:\n",
    "        return 0\n",
    "\n",
    "    precision = 1.0 * num_same / len(response_tokens)\n",
    "    recall = 1.0 * num_same / len(ground_truth_tokens)\n",
    "    f1 = (2 * precision * recall) / (precision + recall)\n",
    "\n",
    "    return f1\n",
    "\n",
    "def evaluate_query_engine(query_engine, dataset):\n",
    "    # Inisialisasi list untuk menyimpan skor\n",
    "    em_scores = []  # Exact Match Scores\n",
    "    f1_scores = []  # F1 Scores\n",
    "    recall_scores = []  # Recall Scores\n",
    "    precision_scores = []  # Precision Scores\n",
    "\n",
    "    # Iterasi melalui setiap data di dataset\n",
    "    for data in dataset:\n",
    "        query = data['query']  # Ambil query dari dataset\n",
    "        ground_truth = data['ground_truth']  # Ambil ground truth dari dataset\n",
    "\n",
    "        # Dapatkan respons dari query engine\n",
    "        response_obj = query_engine.query(query)\n",
    "\n",
    "        # Ekstrak teks dari objek respons\n",
    "        # Modifikasi baris ini sesuai dengan cara objek respons menyimpan teks\n",
    "        response_text = response_obj.text if hasattr(response_obj, 'text') else str(response_obj)\n",
    "\n",
    "        # Hitung skor Exact Match\n",
    "        em = calculate_exact_match(response_text, ground_truth)\n",
    "        # Hitung skor F1\n",
    "        f1 = calculate_f1(response_text, ground_truth)\n",
    "\n",
    "        # Hitung skor Recall\n",
    "        recall = len(set(response_text) & set(ground_truth)) / len(set(ground_truth))\n",
    "        # Hitung skor Precision\n",
    "        precision = len(set(response_text) & set(ground_truth)) / len(set(response_text)) if response_text else 0\n",
    "\n",
    "        # Tambahkan skor ke list masing-masing\n",
    "        em_scores.append(em)\n",
    "        f1_scores.append(f1)\n",
    "        recall_scores.append(recall)\n",
    "        precision_scores.append(precision)\n",
    "\n",
    "    # Hitung rata-rata untuk setiap skor\n",
    "    avg_em = np.mean(em_scores)\n",
    "    avg_f1 = np.mean(f1_scores)\n",
    "    avg_recall = np.mean(recall_scores)\n",
    "    avg_precision = np.mean(precision_scores)\n",
    "\n",
    "    # Kembalikan rata-rata skor\n",
    "    return avg_em, avg_f1, avg_recall, avg_precision\n",
    "\n",
    "\n",
    "avg_em, avg_f1, avg_recall, avg_precision = evaluate_query_engine(query_engine, dataset)\n",
    "# Sekarang, cetak nilai-nilai tersebut\n",
    "print(f\"Average Exact Match (EM): {avg_em}\")\n",
    "print(f\"Average F1 Score: {avg_f1}\")\n",
    "print(f\"Average Recall: {avg_recall}\")\n",
    "print(f\"Average Precision: {avg_precision}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness Score: 0.0\n",
      "relevancy Score: 0.0\n",
      "correctness score :  1.0\n"
     ]
    }
   ],
   "source": [
    "score = get_eval_results(\"faithfulness\", eval_results)\n",
    "score = get_eval_results(\"relevancy\", eval_results)\n",
    "print(\"correctness score : \",CorrectScore )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
